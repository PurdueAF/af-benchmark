{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c49fa3-5a71-422c-826f-61447b1d1d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import uproot\n",
    "import tqdm\n",
    "import math\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from dask_gateway import Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba587-1c2c-4783-8e9a-1207d9f357b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file = \"root://eos.cms.rcac.purdue.edu//store/data/Run2016B/SingleMuon/NANOAOD/02Apr2020_ver2-v1/20000/014D129C-DD09-A748-BB1C-81184C4A8DDD.root\"\n",
    "prefix = \"root://eos.cms.rcac.purdue.edu/\"\n",
    "prefix_mount = \"/eos/purdue/\"\n",
    "\n",
    "datasets = [\n",
    "    # 2016\n",
    "    \"/store/data/Run2016B/SingleMuon/NANOAOD/02Apr2020_ver2-v1\",\n",
    "    \"/store/data/Run2016C/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2016D/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2016E/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2016F/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2016G/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2016H/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    #2017\n",
    "    \"/store/data/Run2017B/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2017C/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2017D/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2017E/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2017F/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    #2018\n",
    "    \"/store/data/Run2018A/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2018B/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2018C/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "    \"/store/data/Run2018D/SingleMuon/NANOAOD/02Apr2020-v1\",\n",
    "]\n",
    "\n",
    "# all ROOT files in datasets\n",
    "files = []\n",
    "for dataset in datasets:\n",
    "    ds_files = glob.glob(prefix_mount+dataset+\"/*/*root\")\n",
    "    print(f\"{dataset}: {len(ds_files)}\")\n",
    "    files.extend(ds_files)\n",
    "\n",
    "# replace explicit path /eos/purdue with XRootD prefix\n",
    "files = [f.replace(prefix_mount, prefix) for f in files]\n",
    "\n",
    "# files = [files[0], files[1]]\n",
    "print(len(files), \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801e61a-79cb-4186-9175-f0560be1413d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_columns(file, fraction=1):\n",
    "    '''\n",
    "        Structure of a NanoAOD file looks like this:\n",
    "          - branch1\n",
    "            - leaf1\n",
    "            - leaf2\n",
    "          - branch2\n",
    "            - leaf1\n",
    "            - leaf2\n",
    "            - leaf3\n",
    "        We will return list of branches/leaves in the following format:\n",
    "          [\n",
    "            [branch1, leaf1],\n",
    "            [branch1, leaf2],\n",
    "            [branch2, leaf1],\n",
    "            [branch2, leaf2],\n",
    "            [branch2, leaf3],\n",
    "          ]\n",
    "    '''\n",
    "\n",
    "    # full NanoAOD event\n",
    "    events = NanoEventsFactory.from_root(\n",
    "        file,\n",
    "        schemaclass=NanoAODSchema.v6,\n",
    "        uproot_options={\"timeout\": 120}\n",
    "    ).events()\n",
    "\n",
    "    all_columns = np.empty((0, 2), dtype=float)\n",
    "\n",
    "    # loop over branches\n",
    "    for branch in events.fields:\n",
    "        # loop over leaves\n",
    "        for leaf in events[branch].fields:\n",
    "            all_columns = np.append(all_columns, [np.array([branch, leaf])], axis=0)\n",
    "\n",
    "    # select a fraction of leaves\n",
    "    columns_subset = all_columns[:math.ceil(fraction * len(all_columns))]\n",
    "\n",
    "    return columns_subset\n",
    "\n",
    "\n",
    "# Workflow to run for each file\n",
    "def process(file, columns=[]):\n",
    "    events = NanoEventsFactory.from_root(\n",
    "        file,\n",
    "        schemaclass=NanoAODSchema.v6,\n",
    "        uproot_options={\"timeout\": 120}\n",
    "    ).events()\n",
    "\n",
    "    # We will compute mean values for a given subset of columns.\n",
    "    # This way we can be sure that we access every element in a column.\n",
    "    mean_values = {}\n",
    "    for column in columns:\n",
    "        branch = column[0]\n",
    "        leaf = column[1]\n",
    "        if leaf in events[branch].fields:\n",
    "            mean_values[f\"{branch}_{leaf}\"] = np.mean(events[branch][leaf])\n",
    "        else:\n",
    "            mean_values[f\"{branch}_{leaf}\"] = 0\n",
    "\n",
    "    nevents = len(events)\n",
    "    return nevents, mean_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a2cb5-69ee-430c-86d8-e4a15fcfa42c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Measure time for a list of files\n",
    "def run_benchmark(process, files, columns=[], parallel=False, client=None):\n",
    "    tick = time.time()\n",
    "\n",
    "    nevts_total = 0\n",
    "\n",
    "    if parallel:\n",
    "        # Parallel processing using Dask\n",
    "        if not client:\n",
    "            raise \"Dask client is missing!\"\n",
    "        futures = client.map(partial(process, columns=columns), files)\n",
    "        results = client.gather(futures)\n",
    "        for r in results:\n",
    "            nevts, mean_vals = r\n",
    "            nevts_total += nevts\n",
    "    else:\n",
    "        # Sequential processing\n",
    "        for file in tqdm.tqdm(files):\n",
    "            nevts, mean_vals = process(file, columns=columns)\n",
    "            # print(mean_vals)\n",
    "            nevts_total += nevts\n",
    "\n",
    "    tock = time.time()\n",
    "    elapsed = tock - tick\n",
    "\n",
    "    print(nevts_total, \"events\")\n",
    "    print(round(elapsed,3), \"s\")\n",
    "    print(nevts_total/elapsed, \"evts/s\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af180fe8-b241-4d74-a4d8-ca6969eba294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = get_columns(files[0], fraction=0.02405)\n",
    "print(len(columns), \"branches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7fa55-8366-4489-bf99-07d960dad627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sequential processing\n",
    "#run_benchmark(process, files, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c499d-5c83-472f-8a28-0d143f1d679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster(\n",
    "    # reservation=\"DASKTEST\",\n",
    "    queue=\"cms-express\",\n",
    "    env={\n",
    "        \"PYTHONPATH\": \"/depot/cms/private/users/dkondra/af-benchmark\",\n",
    "        \"X509_USER_PROXY\": \"/depot/cms/private/users/dkondra/x509up_u616617\"\n",
    "    }\n",
    ")\n",
    "cluster.scale(100)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87576fe-1dc8-4d1c-98f8-f3fe9f6896f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process via Dask Gateway cluster\n",
    "run_benchmark(process, files, columns, parallel=True, client=cluster.get_client())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5eac0-8d3c-45b4-ac5a-c0a182d6b9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ed48f-1e74-4f37-9ef0-f531356d4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "# List existing clusters\n",
    "gateway.list_clusters()\n",
    "# options = gateway.cluster_options()\n",
    "# options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0c425-9c16-4014-8f8a-1ba9161154f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"d6e87428c2f04da2964690275284afb3\"\n",
    "cluster = gateway.connect(name)\n",
    "client = gateway.connect(name).get_client()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb13d7d-c21f-4b0f-842c-4a0fad305ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 kernel [ML]",
   "language": "python",
   "name": "python3-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
